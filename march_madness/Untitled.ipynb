{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create train and test set\n",
    "def split_mask(dftouse, split_size = 0.7):\n",
    "    itrain, itest = train_test_split(xrange(dftouse.shape[0]), train_size=split_size)\n",
    "    mask=np.ones(dftouse.shape[0], dtype='int')\n",
    "    mask[itrain]=1\n",
    "    mask[itest]=0\n",
    "    mask = (mask==1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_jobs, n_folds, score_func, verbose):\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, verbose=verbose, scoring=score_func)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "    best = gs.best_estimator_\n",
    "    return best, gs.best_params_\n",
    "\n",
    "def do_classify(clf, parameters, X, y, mask=None, score_func='f1', n_folds=5, n_jobs=1, verbose=False):\n",
    "    if mask is not None:\n",
    "        mask = split_mask(X)\n",
    "    Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    clf, best_params_ = cv_optimize(clf, parameters, Xtrain, ytrain, n_jobs=n_jobs, n_folds=n_folds, verbose=verbose, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    train_preds = clf.predict(Xtrain)\n",
    "    test_preds = clf.predict(Xtest)\n",
    "    training_accuracy = log_loss(ytrain, train_preds)\n",
    "    test_accuracy = log_loss(ytest, test_preds)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.4f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.4f\" % (test_accuracy)\n",
    "    #print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest, best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 434 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "seasons = pd.read_csv(\"Seasons.csv\")\n",
    "data_simple = pd.read_csv(\"RegularSeasonCompactResults.csv\")\n",
    "data_detailed = pd.read_csv(\"RegularSeasonDetailedResults.csv\")\n",
    "data_simple_T = pd.read_csv(\"TourneyCompactResults.csv\")\n",
    "data_detailed_T = pd.read_csv(\"TourneyDetailedResults.csv\")\n",
    "teams = pd.read_csv(\"Teams.csv\")\n",
    "seeds = pd.read_csv(\"TourneySeeds.csv\")\n",
    "slots = pd.read_csv(\"TourneySlots.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parseSeed(x):\n",
    "    try:\n",
    "        return int(x[1:])\n",
    "    except ValueError:\n",
    "        return int(x[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def helper(x, df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df_ =  df[sum(df[df.Team == x.Team].index.tolist())+1:]\n",
    "    return pd.DataFrame(zip(*([x.Seed] * df_.shape[0], [x.Team] * df_.shape[0], df_.Seed, df_.Team)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrisize_df(df):\n",
    "    for i in range(df.shape[0]):\n",
    "        try:\n",
    "            final_df = pd.concat([final_df, helper(df.iloc[i], df)])\n",
    "        except UnboundLocalError:\n",
    "            final_df = helper(df.iloc[i], df)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 69 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "teams_2015 = seeds[seeds.Season == 2015]\n",
    "teams_2015.loc[:,'Seed'] = teams_2015.Seed.map(parseSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_final = matrisize_df(teams_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1437</td>\n",
       "      <td>2</td>\n",
       "      <td>1438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1437</td>\n",
       "      <td>3</td>\n",
       "      <td>1328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1437</td>\n",
       "      <td>4</td>\n",
       "      <td>1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1437</td>\n",
       "      <td>5</td>\n",
       "      <td>1320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1437</td>\n",
       "      <td>6</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2     3\n",
       "0  1  1437  2  1438\n",
       "1  1  1437  3  1328\n",
       "2  1  1437  4  1257\n",
       "3  1  1437  5  1320\n",
       "4  1  1437  6  1344"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_preds(filename, year, teams, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"id,pred\\n\")\n",
    "        for t1,t2,p in zip(teams, predictions):\n",
    "            f.write(str(year) + \"_\" + str(t1) + \"_\" + str(t2) + \",\" + str(p) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
