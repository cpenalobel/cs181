{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "import util\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "TEST_DIR = \"test\"\n",
    "\n",
    "call_set = set([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create train and test set\n",
    "def split_mask(dftouse, split_size = 0.7):\n",
    "    itrain, itest = train_test_split(xrange(dftouse.shape[0]), train_size=split_size)\n",
    "    mask=np.ones(dftouse.shape[0], dtype='int')\n",
    "    mask[itrain]=1\n",
    "    mask[itest]=0\n",
    "    mask = (mask==1)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from: train\n",
      "Number of datafiles loaded: 6172 \n",
      "\n",
      "Reading from: test\n",
      "Number of datafiles loaded: 3724Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
      " BEST {'n_estimators': 100, 'max_depth': 25} 0.784259259259 [mean: 0.78426, std: 0.00261, params: {'n_estimators': 100, 'max_depth': 25}]\n",
      "Training classes\n",
      "[ 8  6 12 ...,  8  8  3]\n",
      "Predicted classes\n",
      "[8 6 8 ..., 8 8 3]\n",
      "Training classes, cv\n",
      "[ 8  8  8 ..., 12 10 10]\n",
      "Predicted classes, cv\n",
      "[ 8  8  8 ...,  8 10 10]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.8009\n",
      "Accuracy on crossv data:   0.7797\n",
      "########################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   2 out of   2 | elapsed:    0.9s finished\n"
     ]
    }
   ],
   "source": [
    "## Feature extraction\n",
    "def main():\n",
    "    X_train, t_train, train_ids = create_data_matrix(0, 6172, TRAIN_DIR)\n",
    "    print \"\\n\"\n",
    "    X_test, t_test, test_ids = create_data_matrix(0, 3724, TEST_DIR)\n",
    "    return X_train, t_train, X_test, t_test, train_ids, test_ids\n",
    "\n",
    "    # From here, you can train models (eg by importing sklearn and inputting X_train, t_train).\n",
    "    \n",
    "def write_to_file(filename, pred_ids, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for pred_id, pred in zip(pred_ids, predictions):\n",
    "            f.write(str(pred_id) + \",\" + str(pred) + \"\\n\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    X_train, t_train, X_test, t_test, train_ids, test_ids = main()\n",
    "    \n",
    "    #logreg = LogisticRegression(C=1e5)\n",
    "    #logreg.fit(X_train, t_train)\n",
    "    #preds = logreg.predict(X_test)\n",
    "    \n",
    "    clfForest, _, _, _, _, best_params = do_classify(clfForest, parameters, X_train, t_train, mask=True, n_folds = 2, \n",
    "                                                     n_jobs = 4, verbose=True)\n",
    "    preds = clfForest.predict(X_test)\n",
    "    write_to_file(\"submissions/RandForest.csv\", test_ids, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_to_set(tree):\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        call_set.add(call)\n",
    "\n",
    "def create_data_matrix(start_index, end_index, direc):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    print \"Reading from:\", direc\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "        \n",
    "        if datafile[0] == '.':\n",
    "            datafile = datafile[2:]\n",
    "        \n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break \n",
    "        \n",
    "        print \"\\rNumber of datafiles loaded:\", i+1,\n",
    "        \n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        add_to_set(tree)\n",
    "        this_row = call_feats(tree)\n",
    "        if X is None:\n",
    "            X = this_row \n",
    "        else:\n",
    "            X = np.vstack((X, this_row))\n",
    "\n",
    "    return X, np.array(classes), ids\n",
    "\n",
    "def call_feats(tree):\n",
    "    good_calls = ['sleep', 'dump_line']\n",
    "\n",
    "    call_counter = {}\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 0\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_feat_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_classify(clf, parameters, X, y, mask=None, n_folds=5, n_jobs=4, verbose=False, score_func='f1'):\n",
    "    if mask is not None:\n",
    "        mask = split_mask(X)\n",
    "    X_train, X_cv, y_train, y_cv = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    clf, best_params_ = cv_optimize(clf, parameters, X_train, y_train, n_jobs=n_jobs, n_folds=n_folds, verbose=verbose)\n",
    "    fit=clf.fit(X_train, y_train)\n",
    "    train_preds = clf.predict(X_train)\n",
    "    cv_preds = clf.predict(X_cv)\n",
    "    training_accuracy = predictAccuracy(y_train, train_preds)\n",
    "    cv_accuracy = predictAccuracy(y_cv, cv_preds)\n",
    "    print \"Training classes\"\n",
    "    print y_train\n",
    "    print \"Predicted classes\"\n",
    "    print train_preds\n",
    "    print \"Training classes, cv\"\n",
    "    print y_cv\n",
    "    print \"Predicted classes, cv\"\n",
    "    print cv_preds\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.4f\" % training_accuracy\n",
    "    print \"Accuracy on crossv data:   %0.4f\" % cv_accuracy\n",
    "    print \"########################################################\"\n",
    "    return fit, X_train, y_train, X_cv, y_cv, best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cv_optimize(clf, parameters, X, y, n_jobs, n_folds, verbose):\n",
    "    gs = GridSearchCV(clf, param_grid=parameters, cv=n_folds, n_jobs=n_jobs, verbose=verbose)\n",
    "    gs.fit(X, y)\n",
    "    print \"BEST\", gs.best_params_, gs.best_score_, gs.grid_scores_\n",
    "    best = gs.best_estimator_\n",
    "    return best, gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clfForest = RandomForestClassifier()\n",
    "parameters = {\n",
    "    \"n_estimators\" : [100],\n",
    "#    \"n_estimators\" : [100,200,400,800],\n",
    "    \"max_depth\": [25]\n",
    "#    \"max_depth\": [100,200,400,None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictAccuracy(y1, y2):\n",
    "    return sum(a == b for a,b in zip(y1,y2)) / float(len(y1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
